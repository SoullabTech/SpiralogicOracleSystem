# ðŸŽ¤ Sesame CSM - Local Models Directory

This directory contains cached model files for Maya's offline voice synthesis.

## Contents (after setup)

```
backend/models/sesame/
â”œâ”€â”€ README.md              # This file
â”œâ”€â”€ config.json           # Model configuration  
â”œâ”€â”€ tokenizer.json        # Tokenizer configuration
â”œâ”€â”€ vocab.txt             # Vocabulary file
â”œâ”€â”€ pytorch_model.bin     # Model weights
â”œâ”€â”€ tokenizer_config.json # Tokenizer settings
â””â”€â”€ special_tokens_map.json # Special token mappings
```

## Setup

Run the setup script to populate this directory:

```bash
./scripts/setup-sesame-offline.sh
```

## Model Info

- **Model**: microsoft/DialoGPT-medium
- **Purpose**: Conversational text generation for Maya's voice responses
- **Size**: ~400MB
- **Type**: Offline-capable, no external dependencies after download

## Usage

These models are automatically loaded by the Sesame CSM Docker container when running in offline mode. No manual intervention required.

## GPU Support

Models will automatically use GPU acceleration if available, falling back to CPU mode otherwise.