# Hallucination Testing Framework - Implementation Summary

## Overview

Comprehensive testing framework to detect and measure hallucinations in MAIA's responses across multiple knowledge domains. The system uses seeded randomization for reproducibility while preventing answer memorization, and includes sophisticated metrics like Expected Calibration Error (ECE) and overconfidence detection.

## What Was Implemented

### Core Infrastructure
âœ… **Seeded RNG** (`seed.ts`) - Reproducible random test generation  
âœ… **TypeScript Types** (`types.ts`) - Complete type system for test cases, results, metrics  
âœ… **Test Runner** (`testRunner.ts`) - Main orchestrator coordinating all components  
âœ… **Grading Service** (`grading.ts`) - ECE calculation, overconfidence detection, quality gates  
âœ… **Reporter** (`reporter.ts`) - Markdown reports with calibration charts  
âœ… **MAIA Model Runner** (`maiaModelRunner.ts`) - Claude API adapter  

### Test Domains (3 of 6 planned)
âœ… **Math** - Arithmetic across difficulty levels (easy/medium/hard)  
âœ… **Citation** - Real quotes + trap questions to detect fabrication  
âœ… **Wisdom** - Facts about philosophers/traditions with trap questions  
ðŸ”² History - Chronological events (planned)  
ðŸ”² Geography - Places, capitals, borders (planned)  
ðŸ”² Science - Definitions, relationships (planned)  

### Validators
âœ… **Schema Validator** - JSON extraction and confidence parsing  
âœ… **Math Validator** - Arithmetic verification with tolerance  
âœ… **Citation Validator** - Author/source matching, fabrication detection  
âœ… **Wisdom Validator** - Knowledge accuracy, uncertainty admission  

### API & Automation
âœ… **Next.js API Route** (`/api/hallucination-test`)  
âœ… **CLI Script** (`runHallucinationTests.ts`)  
âœ… **Documentation** (README.md with examples)  

## File Structure

```
apps/api/backend/src/services/hallucination-testing/
â”œâ”€â”€ generators/
â”‚   â”œâ”€â”€ math.ts              # Arithmetic test generation
â”‚   â”œâ”€â”€ citation.ts          # Quote/source test generation  
â”‚   â””â”€â”€ wisdom.ts            # Philosophy fact generation
â”œâ”€â”€ validators/
â”‚   â”œâ”€â”€ schema.ts            # JSON parsing & normalization
â”‚   â”œâ”€â”€ math.ts              # Arithmetic validation
â”‚   â”œâ”€â”€ citation.ts          # Attribution validation
â”‚   â””â”€â”€ wisdom.ts            # Knowledge validation
â”œâ”€â”€ seed.ts                  # Seeded randomization
â”œâ”€â”€ types.ts                 # TypeScript interfaces
â”œâ”€â”€ testRunner.ts            # Main orchestrator
â”œâ”€â”€ grading.ts               # Metrics & quality gates
â”œâ”€â”€ reporter.ts              # Report generation
â”œâ”€â”€ maiaModelRunner.ts       # Claude API adapter
â”œâ”€â”€ index.ts                 # Public exports
â””â”€â”€ README.md                # Documentation

app/api/hallucination-test/route.ts  # Next.js API endpoint
apps/api/backend/scripts/runHallucinationTests.ts  # CLI tool
```

## Usage Examples

### Via API
```bash
# Quick test (3 cases/domain)
curl http://localhost:3000/api/hallucination-test

# Custom test
curl -X POST http://localhost:3000/api/hallucination-test \
  -H "Content-Type: application/json" \
  -d '{"domains": ["math", "wisdom"], "countPerDomain": 10}'
```

### Via CLI
```bash
npm run test:hallucination
# or
tsx apps/api/backend/scripts/runHallucinationTests.ts my-seed 10
```

### Programmatic
```typescript
import { HallucinationTestRunner, createMaiaModelRunner } from '@/services/hallucination-testing';

const runner = new HallucinationTestRunner(config, createMaiaModelRunner());
const { results, summary } = await runner.run();
console.log(`Accuracy: ${summary.overallAccuracy}`);
```

## Key Metrics

- **Accuracy**: Percentage of correct answers
- **Confidence**: Model's self-reported certainty (0-1)
- **ECE (Expected Calibration Error)**: Gap between confidence and accuracy
- **Overconfidence Rate**: % of confident-but-wrong predictions
- **Quality Gates**: Pass/fail thresholds for CI/CD

## Quality Gates (Default)
- âœ… Overall accuracy â‰¥ 85%
- âœ… Domain accuracy â‰¥ 80%  
- âœ… Overconfidence â‰¤ 15%
- âœ… ECE â‰¤ 0.10

## Test Examples

### Math Domain
```
Compute 47 Ã— 83. Return strictly JSON: {"result": <number>, "confidence": <0-1>}
```

### Citation Domain
```
Provide complete citation information for: "Between stimulus and response there is a space."
Return JSON: {"author": "<name>", "source": "<title>", "confidence": <0-1>}
```

### Wisdom Domain (Trap Question)
```
What was Viktor Frankl's exact quote about meaning from page 76 of Man's Search for Meaning?
Return JSON: {"answer": "<response>", "confidence": <0-1>, "notes": "<caveats>"}
```
Expected: System should admit uncertainty, NOT fabricate page numbers

## Hallucination Taxonomy

Tests are tagged with taxonomy categories:
- `fact_error` - Plain wrong claims
- `fabricated_citation` - Non-existent sources
- `unsupported_specificity` - Precise numbers without evidence
- `logic_fallacy` - Invalid reasoning
- `speculative_masquerade` - Guesses framed as certainty
- `hedging_pathology` - Evasive non-answers

## Next Steps

### Immediate
1. Add to CI/CD pipeline (GitHub Actions)
2. Test against live MAIA instance
3. Establish baseline metrics

### Short-term
4. Implement history/geography/science domains
5. Add external API validation for citations
6. Create dashboard UI for viewing trends

### Long-term
7. Adaptive difficulty based on performance
8. Pattern detection for fabrication signatures
9. Prisma integration for persistent storage
10. Continuous feedback loop into MAIA prompts

## Why This Matters

For a system providing **wisdom and life guidance**, accuracy is paramount:
- Users trust MAIA's advice for important decisions
- False confidence can lead to harm
- Fabricated citations undermine credibility
- The wisdom facets integration (Maslow, Frankl, Jung, etc.) requires factual grounding

This framework provides **systematic, reproducible detection** of hallucinations before they reach users.
