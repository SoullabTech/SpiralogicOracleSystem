# ğŸŒ€ Voice Stream QA Ritual

**Purpose:** Validate the full end-to-end pipeline after aligning useMayaStream to the new stream interface.

---

## âœ… Pre-flight

- Backend running on port 3002 (`./start-dev.sh`)
- Frontend running on port 3000 (or auto-shifted 3001/3002)
- Browser console open (for `[VoiceRecorder]` logs)
- Backend terminal visible (for `[Pipeline]` logs)

---

## ğŸ” Step 1 â€“ Recording & Transcript

1. Click record in the UI.
2. Speak: "Hello Maya, can you hear me?"
3. Confirm in browser console:

```
[VoiceRecorder] Final transcript: "Hello Maya, can you hear me?"
[VoiceRecorder] Sending transcript to backend...
```

---

## ğŸ” Step 2 â€“ Backend Reception

1. Check backend logs:

```
[Pipeline] Received transcript: Hello Maya, can you hear me?
[Pipeline] Generating AI response...
```

---

## ğŸ” Step 3 â€“ Prosody & CI Shaping

1. Ensure prosody shaping runs:

```
[Pipeline] Shaped response: ... 
[Pipeline] Prosody â†’ element=air, balance=earth
[Pipeline] Sending shaped text to TTS...
```

---

## ğŸ” Step 4 â€“ TTS Response

1. Confirm TTS request fires:

```
[SesameTTS] TTS success, audio size: XXXXX bytes
[Pipeline] TTS completed: { audioUrl: '...' }
```

2. In browser overlay â†’ TTS stage lights up green.

---

## ğŸ” Step 5 â€“ Audio Playback

1. Browser console should log:

```
[VoiceRecorder] Playing audio response
```

2. UI should show the Recording block pulsing blue again when Maya speaks.
3. You should hear audio output.

---

## ğŸ” Step 6 â€“ Error/Fallback

- If Sesame CI is down:

```
[Pipeline] âš ï¸ CI shaping disabled â†’ using raw TTS
```

- Audio must still play via fallback.

---

## ğŸ¯ Success Metrics

- Transcript logs correctly in frontend + backend.
- Shaped response logged with element + balance.
- Audio generated + played in <2s.
- Overlay shows all stages lit in sequence.
- Fallback TTS works if Sesame is offline.

---

**Usage:** Run this ritual after any changes to the voice streaming pipeline to ensure end-to-end functionality remains intact.